import streamlit as st
import asyncio
import os

# --- ã€é‡è¦ã€‘Streamlitã§éåŒæœŸå‡¦ç†ã‚¨ãƒ©ãƒ¼ã‚’é˜²ããŸã‚ã®ãŠã¾ã˜ãªã„ ---
try:
    asyncio.get_running_loop()
except RuntimeError:
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)

from langchain_community.document_loaders import CSVLoader
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate

# --- è¨­å®š ---
st.set_page_config(page_title="æ£®æ—ãƒŠãƒ¬ãƒƒã‚¸ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ(Geminiç‰ˆ)", page_icon="ğŸŒ²", layout="wide")
st.title("ğŸŒ² æ£®æ—çµŒå–¶ãƒŠãƒ¬ãƒƒã‚¸ãƒœãƒƒãƒˆ (Gemini 2.5)")

# APIã‚­ãƒ¼ã®å–å¾—
if "GOOGLE_API_KEY" not in st.session_state:
    st.session_state.GOOGLE_API_KEY = ""

if "GOOGLE_API_KEY" in st.secrets:
    api_key = st.secrets["GOOGLE_API_KEY"]
else:
    api_key = st.sidebar.text_input("Google API Key", type="password")

if not api_key:
    st.info("å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«Google APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    st.stop()

os.environ["GOOGLE_API_KEY"] = api_key

# --- RAGæ§‹ç¯‰ ---
@st.cache_resource
def build_vector_store():
    # ã€ä¿®æ­£1ã€‘ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’ 'utf-8-sig' ã«å¤‰æ›´ (BOMä»˜ãCSVã«å¯¾å¿œ)
    loader = CSVLoader(
        file_path="data/æ£®æ—ãƒŠãƒ¬ãƒƒã‚¸.csv",
        encoding="utf-8-sig", 
        source_column="è³ªå• (Question)",
        csv_args={
            'delimiter': ',',
            'quotechar': '"'
        }
    )
    docs = loader.load()
    
    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã®è¡¨ç¤ºï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼‰
    if len(docs) > 0:
        st.sidebar.success(f"ğŸ“š ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æˆåŠŸ: {len(docs)}ä»¶")
        with st.sidebar.expander("ãƒ‡ãƒ¼ã‚¿ã®å…ˆé ­ã‚’ç¢ºèª"):
            st.text(docs[0].page_content)
    else:
        st.sidebar.error("âš ï¸ ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸ")

    # Embeddingãƒ¢ãƒ‡ãƒ«
    embeddings = GoogleGenerativeAIEmbeddings(model="models/text-embedding-004")
    
    # ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã®ä½œæˆ
    vectorstore = FAISS.from_documents(docs, embeddings)
    return vectorstore

try:
    vectorstore = build_vector_store()
    # æ¤œç´¢æ•° k=5
    retriever = vectorstore.as_retriever(search_type="similarity", search_kwargs={"k": 5})
except Exception as e:
    st.error(f"ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    st.stop()

# --- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå®šç¾© ---
prompt_template = """ã‚ãªãŸã¯æ£®æ—çµŒå–¶ã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®ã€Œå‚ç…§æƒ…å ±ã€ã®ã¿ã«åŸºã¥ã„ã¦è³ªå•ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚
ã‚‚ã—å‚ç…§æƒ…å ±ã«ç­”ãˆãŒå«ã¾ã‚Œã¦ã„ãªã„å ´åˆã¯ã€æ­£ç›´ã«ã€Œæƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“ã€ã¨ç­”ãˆã¦ãã ã•ã„ã€‚

å‚ç…§æƒ…å ±:
{context}

è³ªå•:
{question}

å›ç­”:"""

PROMPT = PromptTemplate(template=prompt_template, input_variables=["context", "question"])

# --- Geminiãƒ¢ãƒ‡ãƒ«ã®è¨­å®š ---
llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0)

qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=retriever,
    chain_type_kwargs={"prompt": PROMPT},
    return_source_documents=True 
)

# --- ãƒãƒ£ãƒƒãƒˆUIã®å®Ÿè£… ---
if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        with st.spinner("Gemini 2.5 ãŒæ€è€ƒä¸­..."):
            try:
                response = qa_chain.invoke({"query": prompt})
                answer = response['result']
                source_docs = response['source_documents']

                st.markdown(answer)
                
                # å‚ç…§ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèªã‚¨ãƒªã‚¢
                with st.expander("ğŸ” å‚ç…§ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã™ã‚‹"):
                    for i, doc in enumerate(source_docs):
                        st.markdown(f"**ãƒ©ãƒ³ã‚¯ {i+1}**")
                        # page_contentã‚’è¡¨ç¤ºã—ã¦ã€æ¤œç´¢ãŒæ­£ã—ã„ã‹ç¢ºèª
                        st.text(doc.page_content)

                st.session_state.messages.append({"role": "assistant", "content": answer})
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")